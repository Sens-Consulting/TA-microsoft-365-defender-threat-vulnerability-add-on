import requests
import json
from pathlib import Path
from datetime import datetime
import config


def get_aadToken(resourceAppIdUri):
    # Get azure auth token

    # Don't have credentials in the script. Set up configs in config.py
    tenantId = config.TENANT_ID
    appId = config.CLIENT_ID
    appSecret = config.CLIENT_SECRET

    url = f"https://login.microsoftonline.com/{tenantId}/oauth2/token"
    resourceAppIdUri = resourceAppIdUri
    payload = {
        'resource': resourceAppIdUri,
        'client_id': appId,
        'client_secret': appSecret,
        'grant_type': 'client_credentials'
    }

    response = requests.request("GET", url, data=payload)
    jsonResponse = response.json()
    aadToken = jsonResponse["access_token"]
    return aadToken


def update_checkpoint(export_type):
    # Save statustime to file
    updatestatus = {}
    updatestatus['type'] = export_type
    updatestatus['time'] = datetime.now().strftime("%Y-%m-%dT%H:%M:%S.%f%z")
    path = Path(__file__).parent / "update_checkpoint.json"
    with path.open("a") as f:
        f.write('\n')
        f.write(json.dumps(updatestatus))


def write_results(filename, values):
    # Writing the response to a file
    today = datetime.now().strftime("%Y-%m-%dT%H%M%S")
    path = Path(__file__).parent / f"../data/{today}_defender_{filename}.txt"
    with path.open("w") as f:
        f.write('\n'.join(json.dumps(i) for i in values))


def retrieve_all_records(endpoint, auth_token):
    # Function to get results spanning multiple pages using odata.nextLink
    all_records = []
    headers = {
        'Authorization': 'Bearer ' + auth_token,
        'Content-Type': 'application/json'
    }
    url = endpoint
    while True:
        if not url:
            break
        response = requests.request("GET", url, headers=headers)
        if response.status_code == 200:
            jsonResponse = response.json()
            all_records = all_records + jsonResponse['value']
            try:
                url = jsonResponse['@odata.nextLink']
            except:
                url = False
    return all_records


def get_vulnerabilities_full_export(baseurl, aadToken):
    # Retrieves all active CVEs in the organization as a full JSON export
    url = baseurl + "/api/machines/SoftwareVulnerabilitiesByMachine?pageSize=200000"
    all_vulnerabilites = retrieve_all_records(url, aadToken)
    write_results('vulnerablilties_full_export', all_vulnerabilites)
    update_checkpoint('Full export')


def get_vulnerabilities_delta_export(baseurl, aadToken):
    # Retrives all updates to CVEs since a given point
    headers = {
        'Authorization': 'Bearer ' + aadToken,
        'Content-Type': 'application/json'
    }

    url = baseurl + "/api/machines/SoftwareVulnerabilityChangesByMachine"

    try:
        path = Path(__file__).parent / "update_checkpoint.json"
        with path.open("r") as f:
            for line in f:
                pass
            last_line = line
        updatestatus = json.loads(last_line)

        payload = {
            'sinceTime': updatestatus['time'],
            'pageSize': 200000
        }

        response = requests.request(
            "GET", url, headers=headers, params=payload)
        if response.status_code == 200:
            jsonResponse = response.json()
            values = jsonResponse['value']
            if values:
                write_results('vulnerablilties_delta_export', values)
                # Only updating checkpoint when data has been retrieved.
                update_checkpoint('Delta export')

    except FileNotFoundError:
        pass


def get_machineinfo(baseurl, aadToken):
    # Retrieves a collection of Machines that have communicated with Microsoft Defender for Endpoint cloud.
    url = baseurl + "/api/machines"
    all_machines = retrieve_all_records(url, aadToken)
    write_results('machineinfo', all_machines)


def get_vulnerabilities_description(baseurl, aadToken):
    # Query to get description of the vulnerabilites in the tenant devices
    query = '''DeviceTvmSoftwareVulnerabilitiesKB
    | join kind=innerunique (DeviceTvmSoftwareVulnerabilities) on CveId
    | summarize arg_max(LastModifiedTime, *) by CveId
    | project CveId, CvssScore, IsExploitAvailable, VulnerabilitySeverityLevel, VulnerabilityDescription, LastModifiedTime, PublishedDate, RecommendedSecurityUpdateId'''

    headers = {
        'Authorization': 'Bearer ' + aadToken,
        'Content-Type': 'application/json'
    }

    url = baseurl + "/api/advancedhunting/run"
    data = json.dumps({'Query': query})

    response = requests.request("POST", url, headers=headers, data=data)
    jsonResponse = response.json()
    values = jsonResponse['Results']

    # Writing to file if response has content
    if values:
        write_results('vulnerabilities_description', values)


if __name__ == "__main__":
    url_defender_endpoint = 'https://api-eu.securitycenter.microsoft.com'
    aadToken = get_aadToken(url_defender_endpoint)
    # Running a full export each day between 8 and 9 UTC
    if 8 <= datetime.utcnow().hour and datetime.utcnow().hour < 9:
        get_vulnerabilities_full_export(url_defender_endpoint, aadToken)
    # Running delta export all other times. Must be run with a large enough delta (e.g. 6 hours), since Defender doesn't update tables in real time
    else:
        get_vulnerabilities_delta_export(url_defender_endpoint, aadToken)

    # Collecting Vulnerability descriptions every other day
    if (datetime.today().isoweekday() in [1, 3, 5]) and 4 <= datetime.utcnow().hour and datetime.utcnow().hour < 5:
        url_defender365 = 'https://api.security.microsoft.com'
        aadToken_hunting = get_aadToken(url_defender365)
        get_vulnerabilities_description(url_defender365, aadToken_hunting)

    # Collecting Machineinfo data  
    if 10 <= datetime.utcnow().hour and datetime.utcnow().hour < 11:
        get_machineinfo(url_defender_endpoint, aadToken)
